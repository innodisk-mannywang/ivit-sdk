# iVIT-SDK é–‹ç™¼è€…æŒ‡å—

> **ç‰ˆæœ¬**ï¼š1.0.0
> **æ›´æ–°æ—¥æœŸ**ï¼š2026-01-26
> **ä½œè€…**ï¼šInnodisk AI Team

---

## ç›®éŒ„

1. [ç°¡ä»‹](#ç°¡ä»‹)
2. [å®‰è£æŒ‡å—](#å®‰è£æŒ‡å—)
3. [å¿«é€Ÿå…¥é–€](#å¿«é€Ÿå…¥é–€)
4. [ä¾è§’è‰²çš„é–‹ç™¼æŒ‡å—](#ä¾è§’è‰²çš„é–‹ç™¼æŒ‡å—)
   - [ç³»çµ±æ•´åˆå•† (SI)](#ç³»çµ±æ•´åˆå•†-si)
   - [AI æ‡‰ç”¨é–‹ç™¼è€…](#ai-æ‡‰ç”¨é–‹ç™¼è€…)
   - [åµŒå…¥å¼å·¥ç¨‹å¸«](#åµŒå…¥å¼å·¥ç¨‹å¸«)
   - [å¾Œç«¯å·¥ç¨‹å¸«](#å¾Œç«¯å·¥ç¨‹å¸«)
   - [è³‡æ–™ç§‘å­¸å®¶](#è³‡æ–™ç§‘å­¸å®¶)
5. [æ ¸å¿ƒ API åƒè€ƒ](#æ ¸å¿ƒ-api-åƒè€ƒ)
6. [æœ€ä½³å¯¦å‹™](#æœ€ä½³å¯¦å‹™)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
8. [Model Zoo å®Œæ•´æ¸…å–®](#model-zoo-å®Œæ•´æ¸…å–®)
9. [é™„éŒ„](#é™„éŒ„)

---

## ç°¡ä»‹

### ä»€éº¼æ˜¯ iVIT-SDKï¼Ÿ

**iVIT-SDK**ï¼ˆInnodisk Vision Intelligence Toolkitï¼‰æ˜¯å®œé¼åœ‹éš›ç‚º AI é‹ç®—å¹³å°é–‹ç™¼çš„çµ±ä¸€é›»è…¦è¦–è¦ºæ¨è«–èˆ‡è¨“ç·´ SDKã€‚æœ¬ SDK æä¾›è·¨ç¡¬é«”å¹³å°çš„çµ±ä¸€ API ä»‹é¢ï¼Œè®“é–‹ç™¼è€…èƒ½å¤ ã€Œ**ä¸€æ¬¡é–‹ç™¼ï¼Œå¤šå¹³å°éƒ¨ç½²**ã€ã€‚

### æ ¸å¿ƒåƒ¹å€¼

| ç‰¹è‰² | èªªæ˜ |
|------|------|
| **çµ±ä¸€ API** | ç„¡è«– Intel æˆ– NVIDIAï¼Œä½¿ç”¨ç›¸åŒçš„ç¨‹å¼ç¢¼ï¼ˆQualcomm è¦åŠƒä¸­ï¼‰ |
| **æ¥µç°¡è¨­è¨ˆ** | é¡ä¼¼ Ultralytics çš„ä¸€è¡Œè¼‰å…¥ã€ä¸€è¡Œæ¨è«–é¢¨æ ¼ |
| **é·ç§»å¼å­¸ç¿’** | å…§å»ºè¨“ç·´æ¨¡çµ„ï¼Œæ”¯æ´æ¨¡å‹å¾®èª¿ |
| **å¤šä»»å‹™æ”¯æ´** | åˆ†é¡ã€åµæ¸¬ã€åˆ†å‰²ã€å§¿æ…‹ä¼°è¨ˆ |
| **é›™èª API** | Python å’Œ C++ åŠŸèƒ½å°ç­‰ |

### æ”¯æ´çš„ç¡¬é«”å¹³å°

| å» å•† | ç¡¬é«” | æ¨è«–å¼•æ“ | x86 | ARM |
|------|------|----------|:---:|:---:|
| Intel | CPU / iGPU / NPU / VPU | OpenVINO | âœ… | âœ… |
| NVIDIA | dGPU / Jetson | TensorRT | âœ… | âœ… |
| Qualcomm | IQ9/IQ8/IQ6 (Hexagon NPU) | QNN (è¦åŠƒä¸­) | - | âœ… |

---

## å®‰è£æŒ‡å—

### ç³»çµ±éœ€æ±‚

- **ä½œæ¥­ç³»çµ±**ï¼šUbuntu 20.04+ / Windows 10+
- **Python**ï¼š3.9 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ç¡¬é«”**ï¼šæ”¯æ´çš„ Intelã€NVIDIA æˆ– Qualcomm è£ç½®

### Python å®‰è£

#### æ–¹æ³• 1ï¼šå¾åŸå§‹ç¢¼å®‰è£ï¼ˆæ¨è–¦ï¼‰

```bash
# è¤‡è£½å°ˆæ¡ˆ
git clone https://github.com/innodisk-mannywang/ivit-sdk.git
cd ivit-sdk

# åŸºæœ¬å®‰è£
pip install -e .

# (é¸ç”¨) å®‰è£ Model Zoo æ”¯æ´ï¼ˆè‡ªå‹•ä¸‹è¼‰å’Œè½‰æ›æ¨¡å‹ï¼‰
pip install -e ".[zoo]"

# åŒ…å«è¨“ç·´åŠŸèƒ½ï¼ˆéœ€è¦ PyTorchï¼‰
pip install -e ".[train]"

# åŒ…å«é–‹ç™¼å·¥å…·
pip install -e ".[dev]"

# åŒ…å«æ‰€æœ‰åŠŸèƒ½
pip install -e ".[all]"
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ pip å®‰è£ï¼ˆå¥—ä»¶ç™¼å¸ƒå¾Œï¼‰

```bash
# åŸºæœ¬å®‰è£
pip install ivit-sdk

# (é¸ç”¨) å®‰è£ Model Zoo æ”¯æ´
pip install "ivit-sdk[zoo]"

# åŒ…å«è¨“ç·´åŠŸèƒ½
pip install "ivit-sdk[train]"

# åŒ…å«æ‰€æœ‰åŠŸèƒ½
pip install "ivit-sdk[all]"

# å®‰è£ç‰¹å®šå¾Œç«¯æ”¯æ´
pip install "ivit-sdk[openvino]"    # Intel OpenVINO
pip install "ivit-sdk[tensorrt]"    # NVIDIA TensorRT
```

> **æ³¨æ„**ï¼šç›®å‰å¥—ä»¶å°šæœªç™¼å¸ƒè‡³ PyPIï¼Œè«‹ä½¿ç”¨æ–¹æ³• 1 å¾åŸå§‹ç¢¼å®‰è£ã€‚

> **Model Zoo èªªæ˜**ï¼šä½¿ç”¨ `ivit.zoo.load()` è‡ªå‹•ä¸‹è¼‰æ¨¡å‹æ™‚ï¼Œéœ€è¦å®‰è£ `ultralytics` å¥—ä»¶ä¾†é€²è¡Œæ¨¡å‹è½‰æ›ã€‚è‹¥ä½¿ç”¨æœ¬åœ° ONNX æª”æ¡ˆå‰‡ä¸éœ€è¦ã€‚

### C++ å»ºç½®

#### ç³»çµ±éœ€æ±‚

- **ç·¨è­¯å™¨**ï¼šGCC 9+ / Clang 10+ / MSVC 2019+
- **CMake**ï¼š3.16 æˆ–æ›´é«˜ç‰ˆæœ¬
- **OpenCV**ï¼š4.5 æˆ–æ›´é«˜ç‰ˆæœ¬

#### ä¾è³´å¥—ä»¶å®‰è£ (Ubuntu)

```bash
# åŸºæœ¬å»ºç½®å·¥å…·
sudo apt-get update
sudo apt-get install -y build-essential cmake git

# OpenCV
sudo apt-get install -y libopencv-dev

# (é¸ç”¨) Intel OpenVINO
# åƒè€ƒï¼šhttps://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_linux.html

# (é¸ç”¨) NVIDIA TensorRT
# åƒè€ƒï¼šhttps://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html
```

#### å»ºç½®æ­¥é©Ÿ

```bash
# è¤‡è£½å°ˆæ¡ˆ
git clone https://github.com/innodisk-mannywang/ivit-sdk.git
cd ivit-sdk

# å»ºç«‹å»ºç½®ç›®éŒ„
mkdir build && cd build

# è¨­å®š CMakeï¼ˆæ ¹æ“šéœ€è¦å•Ÿç”¨å¾Œç«¯ï¼‰
cmake .. \
    -DCMAKE_BUILD_TYPE=Release \
    -DIVIT_USE_OPENVINO=ON \
    -DIVIT_USE_TENSORRT=ON \
    -DIVIT_BUILD_EXAMPLES=ON

# å»ºç½®
make -j$(nproc)

# å®‰è£ï¼ˆé¸ç”¨ï¼‰
sudo make install
```

#### CMake é¸é …

| é¸é … | é è¨­å€¼ | èªªæ˜ |
|------|--------|------|
| `DIVIT_USE_OPENVINO` | OFF | å•Ÿç”¨ Intel OpenVINO å¾Œç«¯ |
| `DIVIT_USE_TENSORRT` | OFF | å•Ÿç”¨ NVIDIA TensorRT å¾Œç«¯ |
| `DIVIT_USE_QNN` | OFF | å•Ÿç”¨ Qualcomm QNN å¾Œç«¯ (IQ Series) |
| `DIVIT_BUILD_EXAMPLES` | ON | å»ºç½®ç¯„ä¾‹ç¨‹å¼ |
| `DIVIT_BUILD_TESTS` | OFF | å»ºç½®æ¸¬è©¦ç¨‹å¼ |
| `DIVIT_BUILD_PYTHON` | OFF | å»ºç½® Python ç¶å®š |

#### åœ¨å°ˆæ¡ˆä¸­ä½¿ç”¨

**CMakeLists.txt**ï¼š

```cmake
cmake_minimum_required(VERSION 3.16)
project(my_project)

# å°‹æ‰¾ iVIT-SDK
find_package(ivit REQUIRED)

# å»ºç«‹åŸ·è¡Œæª”
add_executable(my_app main.cpp)
target_link_libraries(my_app PRIVATE ivit::ivit)
```

**pkg-config**ï¼š

```bash
# ç·¨è­¯
g++ -o my_app main.cpp $(pkg-config --cflags --libs ivit)
```

### é©—è­‰å®‰è£

#### Python

```python
import ivit

# æª¢æŸ¥ç‰ˆæœ¬
print(f"iVIT-SDK ç‰ˆæœ¬: {ivit.__version__}")

# æª¢æŸ¥å¯ç”¨è£ç½®
ivit.devices()
```

é æœŸè¼¸å‡ºï¼š
```
iVIT-SDK ç‰ˆæœ¬: 1.0.0
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                   iVIT Available Devices                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ID       â”‚ Name                    â”‚ Backend          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  cpu      â”‚ Intel(R) Xeon(R)        â”‚ openvino         â”‚
â”‚  cuda:0   â”‚ NVIDIA RTX 6000 Ada     â”‚ tensorrt         â”‚
â”‚  cuda:1   â”‚ NVIDIA RTX 6000 Ada     â”‚ tensorrt         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

#### C++

```cpp
#include <iostream>
#include "ivit/ivit.hpp"

int main() {
    // æª¢æŸ¥ç‰ˆæœ¬
    std::cout << "iVIT-SDK Version: " << ivit::version() << std::endl;

    // åˆ—å‡ºå¯ç”¨è£ç½®
    auto devices = ivit::list_devices();
    std::cout << "Available devices: " << devices.size() << std::endl;

    for (const auto& dev : devices) {
        std::cout << "  - " << dev.id << ": " << dev.name
                  << " (" << dev.backend << ")" << std::endl;
    }

    return 0;
}
```

å»ºç½®èˆ‡åŸ·è¡Œï¼š
```bash
cd build
./simple_inference devices
```

é æœŸè¼¸å‡ºï¼š
```
iVIT-SDK Version: 1.0.0
Available devices: 3
  - cpu: Intel(R) Xeon(R) (openvino)
  - cuda:0: NVIDIA RTX 6000 Ada (tensorrt)
  - cuda:1: NVIDIA RTX 6000 Ada (tensorrt)
```

---

## å¿«é€Ÿå…¥é–€

### 30 ç§’å¿«é€Ÿé«”é©—

**æ–¹å¼ä¸€ï¼šä½¿ç”¨ Model Zooï¼ˆæ¨è–¦æ–°æ‰‹ï¼‰**

```python
import ivit

# å¾ Model Zoo è¼‰å…¥æ¨¡å‹ï¼ˆè‡ªå‹•ä¸‹è¼‰ï¼‰
model = ivit.zoo.load("yolov8n")

# åŸ·è¡Œæ¨è«–
results = model("image.jpg")

# é¡¯ç¤ºçµæœ
results.show()
```

> **å¯ç”¨æ¨¡å‹**ï¼š`yolov8n`, `yolov8s`, `yolov8m`, `yolov8l`, `yolov8x`, `yolov8n-cls`, `yolov8s-cls`, `resnet50`, `mobilenetv3`, `efficientnet-b0`, `yolov8n-seg`, `yolov8s-seg`, `yolov8n-pose`, `yolov8s-pose`
>
> å®Œæ•´æ¸…å–®èˆ‡æ•ˆèƒ½æŒ‡æ¨™è«‹åƒè€ƒ [Model Zoo å®Œæ•´æ¸…å–®](#model-zoo-å®Œæ•´æ¸…å–®)ã€‚

**æ–¹å¼äºŒï¼šä½¿ç”¨è‡ªå·±çš„æ¨¡å‹æª”æ¡ˆ**

```python
import ivit

# è¼‰å…¥æœ¬åœ°æ¨¡å‹æª”æ¡ˆï¼ˆéœ€è‡ªå‚™ .onnx/.xml/.engine æª”æ¡ˆï¼‰
model = ivit.load("path/to/your/model.onnx")

# åŸ·è¡Œæ¨è«–
results = model("image.jpg")

# é¡¯ç¤ºçµæœ
results.show()
```

> **âš ï¸ è‡ªå®šç¾©æ¨¡å‹æ³¨æ„äº‹é …**
>
> ä½¿ç”¨é Model Zoo çš„æ¨¡å‹æ™‚ï¼Œå¯èƒ½é‡åˆ°ä»¥ä¸‹å•é¡Œï¼š
>
> | å•é¡Œé¡å‹ | èªªæ˜ | è§£æ±ºæ–¹æ¡ˆ |
> |----------|------|----------|
> | **ä¸æ”¯æ´çš„é‹ç®—å­** | æ¨¡å‹åŒ…å«æ¨è«–å¼•æ“ä¸æ”¯æ´çš„ Op | ç¢ºèª ONNX opset ç‰ˆæœ¬ï¼Œæˆ–ç°¡åŒ–æ¨¡å‹çµæ§‹ |
> | **å‰è™•ç†ä¸åŒ¹é…** | è¼¸å…¥æ ¼å¼èˆ‡é æœŸä¸ç¬¦ï¼ˆRGB/BGRã€æ­£è¦åŒ–æ–¹å¼ï¼‰ | ä½¿ç”¨ `model.set_preprocessor()` è‡ªå®šç¾©å‰è™•ç† |
> | **å¾Œè™•ç†ä¸åŒ¹é…** | è¼¸å‡ºæ ¼å¼èˆ‡å…§å»ºè§£æå™¨ä¸ç¬¦ | ä½¿ç”¨ `model.set_postprocessor()` è‡ªå®šç¾©å¾Œè™•ç† |
> | **è¼¸å…¥å½¢ç‹€éŒ¯èª¤** | æ¨¡å‹é æœŸå›ºå®šå°ºå¯¸æˆ–å‹•æ…‹å°ºå¯¸ | æª¢æŸ¥æ¨¡å‹è¼¸å…¥è¦æ ¼ï¼Œèª¿æ•´åœ–åƒå°ºå¯¸ |
> | **è‡ªå®šç¾©å±¤** | æ¨¡å‹åŒ…å«è‡ªå®šç¾©å¯¦ä½œçš„å±¤ | éœ€å°‡è‡ªå®šç¾©å±¤è½‰ç‚ºæ¨™æº–é‹ç®—å­çµ„åˆ |
>
> **å»ºè­°åšæ³•**ï¼š
> ```python
> # 1. å…ˆæª¢æŸ¥æ¨¡å‹è³‡è¨Š
> model = ivit.load("custom_model.onnx")
> print(f"è¼¸å…¥: {model.input_info}")
> print(f"è¼¸å‡º: {model.output_info}")
>
> # 2. å¦‚æœå‰å¾Œè™•ç†ä¸åŒ¹é…ï¼Œè‡ªå®šç¾©è™•ç†å™¨
> from ivit.core.processors import BasePreProcessor, BasePostProcessor
>
> class MyPreProcessor(BasePreProcessor):
>     def __call__(self, image):
>         # å¯¦ä½œæ‚¨çš„å‰è™•ç†é‚è¼¯
>         ...
>
> class MyPostProcessor(BasePostProcessor):
>     def __call__(self, outputs, original_shape):
>         # å¯¦ä½œæ‚¨çš„å¾Œè™•ç†é‚è¼¯
>         ...
>
> model.set_preprocessor(MyPreProcessor())
> model.set_postprocessor(MyPostProcessor())
> ```
>
> è©³ç´°èªªæ˜è«‹åƒè€ƒ [åµŒå…¥å¼å·¥ç¨‹å¸« - è‡ªå®šç¾©å‰è™•ç†å™¨](#è‡ªå®šç¾©å‰è™•ç†å™¨) ç« ç¯€ã€‚
>
> **ğŸ“˜ å®Œæ•´æ•™å­¸**ï¼š[è‡ªå®šç¾©æ¨¡å‹æ•´åˆæŒ‡å—](./tutorials/custom-model.md) - åŒ…å«ä¸‰å€‹å¯¦éš›ç¯„ä¾‹ï¼šå‰å¾Œè™•ç†ä¸åŒ¹é…ã€ä¸æ”¯æ´çš„é‹ç®—å­ã€è‡ªå®šç¾©è¼¸å‡ºæ ¼å¼ã€‚

> **Model Zoo èªªæ˜**ï¼šiVIT å…§å»º 14 å€‹é è¨“ç·´æ¨¡å‹ï¼Œä½¿ç”¨ `ivit.zoo.load()` æœƒè‡ªå‹•ä¸‹è¼‰æ¨¡å‹åˆ°å¿«å–ç›®éŒ„ä¸¦è‡ªå‹•é…ç½®æ­£ç¢ºçš„å‰å¾Œè™•ç†ã€‚**æ¨è–¦æ–°æ‰‹å„ªå…ˆä½¿ç”¨ Model Zoo**ã€‚è©³è¦‹ [Model Zoo å®Œæ•´æ¸…å–®](#model-zoo-å®Œæ•´æ¸…å–®)ã€‚

### å®Œæ•´ç¯„ä¾‹

```python
import ivit

# 1. æ¢ç´¢å¯ç”¨è£ç½®
print("å¯ç”¨è£ç½®:")
ivit.devices()

# 2. è‡ªå‹•é¸æ“‡æœ€ä½³è£ç½®
best_device = ivit.devices.best()
print(f"æœ€ä½³è£ç½®: {best_device.id} ({best_device.backend})")

# 3. æŸ¥çœ‹ Model Zoo å¯ç”¨æ¨¡å‹
print("å¯ç”¨æ¨¡å‹:")
print(ivit.zoo.list_models())

# 4. å¾ Model Zoo è¼‰å…¥æ¨¡å‹ï¼ˆè‡ªå‹•ä¸‹è¼‰ + æŒ‡å®šè£ç½®ï¼‰
model = ivit.zoo.load("yolov8n", device=best_device)

# 5. åŸ·è¡Œæ¨è«–
results = model("image.jpg")

# 6. è™•ç†çµæœ
print(f"åµæ¸¬åˆ° {len(results)} å€‹ç‰©ä»¶")
for det in results:
    print(f"  - {det.label}: {det.confidence:.2%}")

# 7. è¦–è¦ºåŒ–
results.show()

# 8. å„²å­˜çµæœ
results.save("output.jpg")
```

---

## ä¾è§’è‰²çš„é–‹ç™¼æŒ‡å—

ä¸åŒè§’è‰²çš„é–‹ç™¼è€…æœ‰ä¸åŒçš„éœ€æ±‚ã€‚ä»¥ä¸‹é‡å°äº”ç¨®å¸¸è¦‹è§’è‰²æä¾›å°ˆå±¬çš„é–‹ç™¼æŒ‡å—ã€‚

---

### ç³»çµ±æ•´åˆå•† (SI)

> **ç›®æ¨™**ï¼šå¿«é€Ÿæ•´åˆ AI æ¨è«–åŠŸèƒ½åˆ°ç¾æœ‰ç³»çµ±ä¸­

#### ä½¿ç”¨æƒ…å¢ƒ

- éœ€è¦åœ¨çŸ­æ™‚é–“å…§å®Œæˆ POC
- å®¢æˆ¶ç’°å¢ƒå¤šæ¨£ï¼Œéœ€è¦è·¨å¹³å°æ”¯æ´
- é‡è¦– API çš„ç©©å®šæ€§å’ŒéŒ¯èª¤è™•ç†

#### å¿«é€Ÿæ•´åˆç¯„ä¾‹

```python
import ivit

# ============================================================
# æƒ…å¢ƒï¼š5 åˆ†é˜å…§å®ŒæˆåŸºæœ¬æ¨è«–æ•´åˆ
# ============================================================

# æ­¥é©Ÿ 1ï¼šæª¢æŸ¥å¯ç”¨è£ç½®
devices = ivit.devices()
print(f"æ‰¾åˆ° {len(devices)} å€‹å¯ç”¨è£ç½®")

# æ­¥é©Ÿ 2ï¼šè‡ªå‹•é¸æ“‡æœ€ä½³è£ç½®ï¼ˆç„¡éœ€æ‰‹å‹•æŒ‡å®šï¼‰
best = ivit.devices.best()
print(f"è‡ªå‹•é¸æ“‡: {best.id} ({best.name})")

# æ­¥é©Ÿ 3ï¼šè¼‰å…¥æ¨¡å‹
# æ–¹å¼ Aï¼šä½¿ç”¨ Model Zooï¼ˆå¿«é€Ÿé©—è­‰ï¼‰
model = ivit.zoo.load("yolov8n", device=best)

# æ–¹å¼ Bï¼šä½¿ç”¨å®¢æˆ¶æä¾›çš„æ¨¡å‹æª”æ¡ˆ
# model = ivit.load("customer_model.onnx", device=best)

# æ­¥é©Ÿ 4ï¼šåŸ·è¡Œæ¨è«–
results = model("input.jpg")

# æ­¥é©Ÿ 5ï¼šå–å¾—çµæ§‹åŒ–çµæœ
output = results.to_dict()
print(f"åµæ¸¬çµæœ: {output}")
```

#### è£ç½®æ¢ç´¢ API

```python
import ivit

# åˆ—å‡ºæ‰€æœ‰è£ç½®
all_devices = ivit.devices()

# å–å¾—ç‰¹å®šé¡å‹è£ç½®
cpu = ivit.devices.cpu()        # CPU è£ç½®
cuda = ivit.devices.cuda()      # NVIDIA GPU
npu = ivit.devices.npu()        # Intel NPU

# è‡ªå‹•é¸æ“‡æœ€ä½³è£ç½®
best_perf = ivit.devices.best()                    # æ•ˆèƒ½å„ªå…ˆ
best_eff = ivit.devices.best("efficiency")         # æ•ˆç‡å„ªå…ˆ

# å–å¾—è£ç½®è©³ç´°è³‡è¨Š
device = ivit.devices.best()
print(f"è£ç½® ID: {device.id}")
print(f"è£ç½®åç¨±: {device.name}")
print(f"å¾Œç«¯å¼•æ“: {device.backend}")
print(f"è£ç½®é¡å‹: {device.type}")
```

#### éŒ¯èª¤è™•ç†æ©Ÿåˆ¶

```python
import ivit
from ivit import (
    IVITError,
    ModelLoadError,
    DeviceNotFoundError,
    InferenceError,
    ConfigurationError,
)

def safe_inference(model_path, image_path):
    """å®‰å…¨çš„æ¨è«–å‡½æ•¸ï¼ŒåŒ…å«å®Œæ•´éŒ¯èª¤è™•ç†"""
    try:
        # è¼‰å…¥æ¨¡å‹
        model = ivit.load(model_path)

        # åŸ·è¡Œæ¨è«–
        results = model(image_path)

        return {"success": True, "results": results.to_dict()}

    except ModelLoadError as e:
        # æ¨¡å‹è¼‰å…¥å¤±æ•—
        return {
            "success": False,
            "error_type": "ModelLoadError",
            "message": str(e),
            "suggestion": "è«‹ç¢ºèªæ¨¡å‹è·¯å¾‘å’Œæ ¼å¼æ˜¯å¦æ­£ç¢º"
        }

    except DeviceNotFoundError as e:
        # è£ç½®ä¸å¯ç”¨
        return {
            "success": False,
            "error_type": "DeviceNotFoundError",
            "message": str(e),
            "suggestion": "è«‹åŸ·è¡Œ ivit.devices() ç¢ºèªå¯ç”¨è£ç½®"
        }

    except InferenceError as e:
        # æ¨è«–éŒ¯èª¤
        return {
            "success": False,
            "error_type": "InferenceError",
            "message": str(e),
            "suggestion": "è«‹æª¢æŸ¥è¼¸å…¥åœ–åƒæ ¼å¼å’Œå°ºå¯¸"
        }

    except IVITError as e:
        # å…¶ä»– iVIT éŒ¯èª¤
        return {
            "success": False,
            "error_type": "IVITError",
            "message": str(e)
        }

# ä½¿ç”¨ç¯„ä¾‹
result = safe_inference("model.onnx", "image.jpg")
if result["success"]:
    print("æ¨è«–æˆåŠŸï¼")
else:
    print(f"éŒ¯èª¤: {result['message']}")
    print(f"å»ºè­°: {result.get('suggestion', 'ç„¡')}")
```

#### SI æœ€ä½³å¯¦å‹™

1. **ä½¿ç”¨ `ivit.devices.best()` è‡ªå‹•é¸æ“‡è£ç½®**
2. **ç¸½æ˜¯åŒ…è£éŒ¯èª¤è™•ç†é‚è¼¯**
3. **ä½¿ç”¨ `results.to_dict()` å–å¾—çµæ§‹åŒ–è¼¸å‡º**
4. **æ¸¬è©¦å¤šç¨®ç¡¬é«”ç’°å¢ƒ**

#### C++ ç¯„ä¾‹

```cpp
#include "ivit/ivit.hpp"
#include <opencv2/opencv.hpp>

using namespace ivit;

int main() {
    // Step 1: è£ç½®æ¢ç´¢
    auto devices = list_devices();
    std::cout << "Found " << devices.size() << " devices" << std::endl;

    auto best = get_best_device();
    std::cout << "Best device: " << best.id << std::endl;

    // Step 2: è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ load_model APIï¼‰
    LoadConfig config;
    config.device = best.id;
    auto model = load_model("yolov8n.onnx", config);

    // Step 3: å®‰å…¨æ¨è«–
    try {
        cv::Mat image = cv::imread("image.jpg");
        auto results = model->predict(image);

        std::cout << "Detections: " << results.detections.size() << std::endl;
        std::cout << "Inference time: " << results.inference_time_ms << " ms" << std::endl;

        // è¼¸å‡ºåµæ¸¬çµæœ
        for (const auto& det : results.detections) {
            std::cout << det.label << ": " << det.confidence << std::endl;
        }

    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
    }

    return 0;
}
```

**å®Œæ•´ç¯„ä¾‹**ï¼š`examples/cpp/si_quickstart.cpp`

```bash
# å»ºç½®èˆ‡åŸ·è¡Œ
cd build && make si_quickstart
./si_quickstart image.jpg model.onnx
```

---

### AI æ‡‰ç”¨é–‹ç™¼è€…

> **ç›®æ¨™**ï¼šè¨“ç·´å’Œéƒ¨ç½²è‡ªå®šç¾© AI æ¨¡å‹

#### ä½¿ç”¨æƒ…å¢ƒ

- éœ€è¦å¾®èª¿é è¨“ç·´æ¨¡å‹ä»¥é©æ‡‰ç‰¹å®šå ´æ™¯
- è™•ç†å®¢æˆ¶è‡ªæœ‰è³‡æ–™é›†
- éœ€è¦å®Œæ•´çš„è¨“ç·´ã€é©—è­‰ã€åŒ¯å‡ºæµç¨‹

#### å®Œæ•´è¨“ç·´æµç¨‹

```python
import ivit
from ivit.train import (
    Trainer,
    ImageFolderDataset,
    EarlyStopping,
    ModelCheckpoint,
    ProgressLogger,
)

# ============================================================
# æƒ…å¢ƒï¼šä½¿ç”¨é·ç§»å¼å­¸ç¿’è¨“ç·´è‡ªå®šç¾©åˆ†é¡å™¨
# ============================================================

# æ­¥é©Ÿ 1ï¼šæº–å‚™è³‡æ–™é›†
# è³‡æ–™å¤¾çµæ§‹:
# my_dataset/
#   â”œâ”€â”€ cat/
#   â”‚   â”œâ”€â”€ image1.jpg
#   â”‚   â””â”€â”€ image2.jpg
#   â””â”€â”€ dog/
#       â”œâ”€â”€ image1.jpg
#       â””â”€â”€ image2.jpg

train_dataset = ImageFolderDataset(
    root="./my_dataset",
    train_split=0.8,
    split="train"
)
val_dataset = ImageFolderDataset(
    root="./my_dataset",
    train_split=0.8,
    split="val"
)

print(f"è¨“ç·´é›†å¤§å°: {len(train_dataset)}")
print(f"é©—è­‰é›†å¤§å°: {len(val_dataset)}")
print(f"é¡åˆ¥æ•¸: {train_dataset.num_classes}")
print(f"é¡åˆ¥åç¨±: {train_dataset.class_names}")

# æ­¥é©Ÿ 2ï¼šå»ºç«‹è¨“ç·´å™¨
trainer = Trainer(
    model="resnet50",           # å¯é¸: resnet18/34/50/101, efficientnet_b0-b2, mobilenet_v2/v3
    dataset=train_dataset,
    val_dataset=val_dataset,
    epochs=20,
    learning_rate=0.001,
    batch_size=32,
    device="cuda:0",
    freeze_backbone=True,       # é·ç§»å¼å­¸ç¿’: å‡çµéª¨å¹¹ç¶²è·¯
    optimizer="adam",           # å¯é¸: adam, adamw, sgd
)

# æ­¥é©Ÿ 3ï¼šè¨­å®šå›èª¿
callbacks = [
    EarlyStopping(patience=5, monitor="val_loss"),
    ModelCheckpoint("best_model.pt", monitor="val_accuracy"),
    ProgressLogger(),
]

# æ­¥é©Ÿ 4ï¼šé–‹å§‹è¨“ç·´
history = trainer.fit(callbacks=callbacks)

# æ­¥é©Ÿ 5ï¼šè©•ä¼°æ¨¡å‹
metrics = trainer.evaluate()
print(f"æœ€çµ‚æº–ç¢ºç‡: {metrics['accuracy']:.2%}")

# æ­¥é©Ÿ 6ï¼šåŒ¯å‡ºæ¨¡å‹
trainer.export("my_model.onnx", format="onnx", quantize="fp16")
```

#### æ”¯æ´çš„é è¨“ç·´æ¨¡å‹

| é¡åˆ¥ | æ¨¡å‹ |
|------|------|
| ResNet | resnet18, resnet34, resnet50, resnet101 |
| EfficientNet | efficientnet_b0, efficientnet_b1, efficientnet_b2 |
| MobileNet | mobilenet_v2, mobilenet_v3_small, mobilenet_v3_large |
| VGG | vgg16, vgg19 |
| DenseNet | densenet121 |

#### è³‡æ–™å¢å¼·

```python
from ivit.train import (
    Compose,
    Resize,
    RandomHorizontalFlip,
    RandomVerticalFlip,
    RandomRotation,
    ColorJitter,
    Normalize,
    ToTensor,
)

# è‡ªå®šç¾©è¨“ç·´å¢å¼·
train_augmentation = Compose([
    Resize(224),
    RandomHorizontalFlip(p=0.5),
    RandomRotation(degrees=15),
    ColorJitter(brightness=0.2, contrast=0.2),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensor(),
])

# é©—è­‰å¢å¼·ï¼ˆä¸å«éš¨æ©Ÿè®Šæ›ï¼‰
val_augmentation = Compose([
    Resize(224),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensor(),
])

# å¥—ç”¨å¢å¼·
image = train_augmentation(original_image)
```

#### æ”¯æ´çš„è³‡æ–™é›†æ ¼å¼

**1. ImageFolder æ ¼å¼**
```python
from ivit.train import ImageFolderDataset

dataset = ImageFolderDataset(
    root="./data",
    train_split=0.8,
    split="train"
)
```

**2. COCO æ ¼å¼**
```python
from ivit.train import COCODataset

dataset = COCODataset(
    images_dir="./coco/images",
    annotations_file="./coco/annotations.json"
)
```

**3. YOLO æ ¼å¼**
```python
from ivit.train import YOLODataset

dataset = YOLODataset(
    images_dir="./yolo/images",
    labels_dir="./yolo/labels",
    class_names=["cat", "dog", "bird"]
)
```

#### è¨“ç·´å›èª¿

```python
from ivit.train import (
    EarlyStopping,
    ModelCheckpoint,
    ProgressLogger,
    LRScheduler,
    TensorBoardLogger,
)

# æ—©åœï¼šç•¶é©—è­‰æå¤±ä¸å†æ”¹å–„æ™‚åœæ­¢è¨“ç·´
early_stop = EarlyStopping(
    patience=5,
    monitor="val_loss",
    min_delta=0.001
)

# æ¨¡å‹æª¢æŸ¥é»ï¼šå„²å­˜æœ€ä½³æ¨¡å‹
checkpoint = ModelCheckpoint(
    filepath="best_model.pt",
    monitor="val_accuracy",
    save_best_only=True
)

# é€²åº¦è¨˜éŒ„
progress = ProgressLogger()

# å­¸ç¿’ç‡èª¿æ•´
lr_scheduler = LRScheduler(
    schedule_type="step",
    step_size=10,
    gamma=0.1
)

# TensorBoard æ—¥èªŒ
tensorboard = TensorBoardLogger(log_dir="./logs")

# ä½¿ç”¨æ‰€æœ‰å›èª¿
trainer.fit(callbacks=[early_stop, checkpoint, progress, lr_scheduler, tensorboard])
```

#### æ¨¡å‹åŒ¯å‡º

```python
# åŒ¯å‡ºç‚º ONNXï¼ˆè·¨å¹³å°ï¼‰
trainer.export("model.onnx", format="onnx", quantize="fp16")

# åŒ¯å‡ºç‚º TorchScript
trainer.export("model.pt", format="torchscript")

# åŒ¯å‡ºç‚º OpenVINO IRï¼ˆIntel å„ªåŒ–ï¼‰
trainer.export("model.xml", format="openvino", quantize="int8")

# åŒ¯å‡ºç‚º TensorRT Engineï¼ˆNVIDIA å„ªåŒ–ï¼‰
trainer.export("model.engine", format="tensorrt", quantize="fp16")
```

#### C++ èªªæ˜

> **Note**: è¨“ç·´åŠŸèƒ½ç›®å‰åƒ…æ”¯æ´ Python APIï¼Œå› ç‚ºåº•å±¤ä¾è³´ PyTorch ç”Ÿæ…‹ç³»çµ±ã€‚C++ API å°ˆæ³¨æ–¼æ¨è«–éƒ¨ç½²ã€‚
>
> è¨“ç·´å®Œæˆå¾Œï¼Œå¯å°‡æ¨¡å‹åŒ¯å‡ºç‚º ONNX æ ¼å¼ï¼Œå†ä½¿ç”¨ C++ API é€²è¡Œéƒ¨ç½²ï¼š
>
> ```cpp
> // è¼‰å…¥ Python è¨“ç·´å¾ŒåŒ¯å‡ºçš„æ¨¡å‹
> ivit::LoadConfig config;
> config.device = "cuda:0";
> auto model = ivit::load_model("my_trained_model.onnx", config);
> auto results = model->predict(image);
> ```

---

### åµŒå…¥å¼å·¥ç¨‹å¸«

> **ç›®æ¨™**ï¼šåœ¨é‚Šç·£è£ç½®ä¸Šå¯¦ç¾ä½å»¶é²ã€é«˜æ•ˆèƒ½æ¨è«–

#### ä½¿ç”¨æƒ…å¢ƒ

- éœ€è¦å„ªåŒ–æ¨è«–æ•ˆèƒ½å’Œè¨˜æ†¶é«”ä½¿ç”¨
- é‡å°ç‰¹å®šç¡¬é«”é€²è¡Œèª¿å„ª
- é—œæ³¨å‰å¾Œè™•ç†çš„æ•ˆèƒ½

#### Runtime é…ç½®

```python
import ivit

# ============================================================
# æƒ…å¢ƒï¼šé‡å°ç‰¹å®šç¡¬é«”å„ªåŒ–æ¨è«–æ•ˆèƒ½
# ============================================================

# è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ Model Zoo æˆ–æœ¬åœ°æª”æ¡ˆçš†å¯ï¼‰
model = ivit.zoo.load("yolov8n", device="cuda:0")
# æˆ–ä½¿ç”¨æœ¬åœ°æª”æ¡ˆ: model = ivit.load("yolov8n.onnx", device="cuda:0")

# --- OpenVINO é…ç½®ï¼ˆIntel ç¡¬é«”ï¼‰---
model.configure_openvino(
    performance_mode="LATENCY",      # LATENCY æˆ– THROUGHPUT
    num_streams=1,                   # æ¨è«–ä¸²æµæ•¸
    inference_precision="FP16",      # ç²¾åº¦
    enable_cpu_pinning=True,         # CPU æ ¸å¿ƒç¶å®š
)

# --- TensorRT é…ç½®ï¼ˆNVIDIA ç¡¬é«”ï¼‰---
model.configure_tensorrt(
    workspace_size=1 << 30,          # 1GB å·¥ä½œç©ºé–“
    fp16=True,                       # å•Ÿç”¨ FP16
    int8=False,                      # INT8 éœ€è¦æ ¡æ­£è³‡æ–™
    dla_core=-1,                     # DLA æ ¸å¿ƒï¼ˆJetsonï¼‰
    builder_optimization_level=3,   # å„ªåŒ–ç­‰ç´šï¼ˆ0-5ï¼‰
    enable_sparsity=True,            # ç¨€ç–åŠ é€Ÿ
)

# --- QNN é…ç½®ï¼ˆQualcomm IQ Series ç¡¬é«”ï¼‰--- (è¦åŠƒä¸­ï¼Œå°šæœªæä¾›)
model.configure_qnn(
    backend="htp",                   # cpu, gpu, htp (Hexagon Tensor Processor)
    performance_profile="HIGH_PERFORMANCE",
    htp_precision="fp16",            # fp16, int8
)

# é ç†±æ¨è«–ï¼ˆé‡è¦ï¼ï¼‰
model.warmup(iterations=10)
```

#### å‰å¾Œè™•ç†å™¨

```python
from ivit.core.processors import (
    get_preprocessor,
    get_postprocessor,
    register_preprocessor,
    register_postprocessor,
    BasePreProcessor,
    BasePostProcessor,
)
import numpy as np
import time

# ============================================================
# æƒ…å¢ƒï¼šé©—è­‰å’Œå„ªåŒ–å‰å¾Œè™•ç†æ•ˆèƒ½
# ============================================================

# å–å¾—å…§å»ºå‰è™•ç†å™¨
letterbox = get_preprocessor("letterbox")
center_crop = get_preprocessor("center_crop")

# å–å¾—å…§å»ºå¾Œè™•ç†å™¨
yolo_post = get_postprocessor("yolo")
cls_post = get_postprocessor("classification")

# æ•ˆèƒ½æ¸¬è©¦
test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

def benchmark_preprocessor(preprocessor, image, iterations=100):
    """æ¸¬è©¦å‰è™•ç†å™¨æ•ˆèƒ½"""
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = preprocessor(image)
        times.append((time.perf_counter() - start) * 1000)

    return {
        "å¹³å‡è€—æ™‚": f"{np.mean(times):.3f}ms",
        "æœ€å°è€—æ™‚": f"{np.min(times):.3f}ms",
        "æœ€å¤§è€—æ™‚": f"{np.max(times):.3f}ms",
        "æ¨™æº–å·®": f"{np.std(times):.3f}ms",
    }

# æ¸¬è©¦ Letterbox
print("Letterbox æ•ˆèƒ½:")
print(benchmark_preprocessor(letterbox, test_image))

# æ¸¬è©¦ CenterCrop
print("\nCenterCrop æ•ˆèƒ½:")
print(benchmark_preprocessor(center_crop, test_image))
```

#### è‡ªå®šç¾©å‰è™•ç†å™¨

```python
from ivit.core.processors import BasePreProcessor, register_preprocessor
import numpy as np
import cv2

class CustomPreProcessor(BasePreProcessor):
    """è‡ªå®šç¾©å‰è™•ç†å™¨ç¯„ä¾‹"""

    def __init__(self, target_size=(640, 640), normalize=True):
        self.target_size = target_size
        self.normalize = normalize

    def process(self, image: np.ndarray, target_size: tuple = None, **kwargs) -> tuple:
        """
        å‰è™•ç†åœ–åƒã€‚

        Args:
            image: è¼¸å…¥åœ–åƒ (BGR, HWC)
            target_size: ç›®æ¨™å°ºå¯¸ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨ self.target_size

        Returns:
            Tuple of (tensor, preprocess_info)
        """
        if target_size is None:
            target_size = self.target_size

        orig_h, orig_w = image.shape[:2]

        # 1. èª¿æ•´å°ºå¯¸
        resized = cv2.resize(image, target_size)

        # 2. BGR è½‰ RGB
        rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)

        # 3. æ­£è¦åŒ–
        if self.normalize:
            rgb = rgb.astype(np.float32) / 255.0

        # 4. HWC è½‰ NCHW
        transposed = np.transpose(rgb, (2, 0, 1))
        batched = np.expand_dims(transposed, axis=0)

        # å›å‚³ tensor å’Œå‰è™•ç†è³‡è¨Šï¼ˆä¾›å¾Œè™•ç†ä½¿ç”¨ï¼‰
        preprocess_info = {
            "orig_size": (orig_h, orig_w),
            "target_size": target_size,
        }

        return batched, preprocess_info

# è¨»å†Šè‡ªå®šç¾©å‰è™•ç†å™¨
register_preprocessor("custom", CustomPreProcessor)

# ä½¿ç”¨è‡ªå®šç¾©å‰è™•ç†å™¨
model = ivit.load("model.onnx")
model.set_preprocessor(CustomPreProcessor(target_size=(416, 416)))
```

#### è‡ªå®šç¾©å¾Œè™•ç†å™¨

```python
from ivit.core.processors import BasePostProcessor, register_postprocessor
from ivit.core.result import Results
from ivit.core.types import Detection, BBox
import numpy as np

class CustomPostProcessor(BasePostProcessor):
    """è‡ªå®šç¾©å¾Œè™•ç†å™¨ç¯„ä¾‹ï¼šYOLO è¼¸å‡ºè§£æ"""

    def __init__(self, conf_threshold=0.5, iou_threshold=0.45, class_names=None):
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.class_names = class_names or []

    def process(
        self,
        outputs: dict,
        orig_size: tuple,
        preprocess_info: dict = None,
        config=None,
        labels: list = None,
    ) -> Results:
        """
        å¾Œè™•ç†æ¨¡å‹è¼¸å‡ºã€‚

        Args:
            outputs: åŸå§‹æ¨¡å‹è¼¸å‡º
            orig_size: åŸå§‹åœ–åƒå°ºå¯¸ (height, width)
            preprocess_info: å‰è™•ç†è³‡è¨Š
            config: æ¨è«–é…ç½®
            labels: é¡åˆ¥æ¨™ç±¤ï¼ˆè‹¥ç‚º None å‰‡ä½¿ç”¨ self.class_namesï¼‰

        Returns:
            Results ç‰©ä»¶
        """
        results = Results()
        results.image_size = orig_size

        if labels is None:
            labels = self.class_names

        # è§£ææ¨¡å‹è¼¸å‡ºï¼ˆç¯„ä¾‹ï¼‰
        predictions = outputs.get("output", outputs[list(outputs.keys())[0]])

        # éæ¿¾ä½ä¿¡å¿ƒåº¦é æ¸¬
        for pred in predictions:
            confidence = float(pred[4])
            if confidence < self.conf_threshold:
                continue

            class_id = int(pred[5])
            label = labels[class_id] if class_id < len(labels) else f"class_{class_id}"

            det = Detection(
                bbox=BBox(pred[0], pred[1], pred[2], pred[3]),
                class_id=class_id,
                label=label,
                confidence=confidence
            )
            results.detections.append(det)

        # NMSï¼ˆéæ¥µå¤§å€¼æŠ‘åˆ¶ï¼‰
        results.detections = self._nms(results.detections, self.iou_threshold)

        return results

    def _nms(self, detections, iou_threshold):
        """ç°¡å–®çš„ NMS å¯¦ä½œ"""
        if not detections:
            return detections

        # æŒ‰ä¿¡å¿ƒåº¦æ’åº
        detections = sorted(detections, key=lambda x: x.confidence, reverse=True)

        keep = []
        while detections:
            best = detections.pop(0)
            keep.append(best)

            detections = [
                d for d in detections
                if d.class_id != best.class_id or best.bbox.iou(d.bbox) < iou_threshold
            ]

        return keep

# è¨»å†Šä¸¦ä½¿ç”¨
register_postprocessor("custom_yolo", CustomPostProcessor)
model.set_postprocessor(CustomPostProcessor(conf_threshold=0.6, class_names=["person", "car"]))
```

#### åµŒå…¥å¼æœ€ä½³å¯¦å‹™

1. **ä¸€å®šè¦åŸ·è¡Œ warmup** - å‰å¹¾æ¬¡æ¨è«–é€šå¸¸è¼ƒæ…¢
2. **ä½¿ç”¨ FP16 é‡åŒ–** - å¤§å¤šæ•¸æƒ…æ³ä¸‹ç²¾åº¦æå¤±å¯å¿½ç•¥
3. **æ ¹æ“šç¡¬é«”èª¿æ•´é…ç½®** - OpenVINO ç”¨ LATENCY æ¨¡å¼ï¼ŒTensorRT å•Ÿç”¨ CUDA Graph
4. **ç›£æ§å‰è™•ç†è€—æ™‚** - å‰è™•ç†å¯èƒ½ä½”ç¸½è€—æ™‚ 30% ä»¥ä¸Š

#### C++ ç¯„ä¾‹

```cpp
#include "ivit/ivit.hpp"
#include <opencv2/opencv.hpp>
#include <chrono>
#include <vector>
#include <numeric>

using namespace ivit;

int main() {
    // é¸æ“‡è£ç½®
    auto device = get_best_device();
    std::cout << "Using device: " << device.id << std::endl;

    // è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ load_model APIï¼‰
    LoadConfig config;
    config.device = device.id;
    auto model = load_model("yolov8n.onnx", config);

    // Step 1: æ¨¡å‹é ç†±ï¼ˆé‡è¦ï¼ï¼‰
    std::cout << "Warming up..." << std::endl;
    cv::Mat dummy(480, 640, CV_8UC3);
    cv::randu(dummy, cv::Scalar(0), cv::Scalar(255));
    for (int i = 0; i < 10; ++i) {
        model->predict(dummy);
    }

    // Step 2: æ•ˆèƒ½æ¸¬è©¦
    cv::Mat test_image(480, 640, CV_8UC3);
    cv::randu(test_image, cv::Scalar(0), cv::Scalar(255));

    std::vector<double> latencies;
    for (int i = 0; i < 100; ++i) {
        auto start = std::chrono::high_resolution_clock::now();
        model->predict(test_image);
        auto end = std::chrono::high_resolution_clock::now();

        double ms = std::chrono::duration<double, std::milli>(end - start).count();
        latencies.push_back(ms);
    }

    double avg = std::accumulate(latencies.begin(), latencies.end(), 0.0) / latencies.size();
    std::cout << "Average latency: " << avg << " ms" << std::endl;
    std::cout << "FPS: " << 1000.0 / avg << std::endl;

    // Note: Runtime é…ç½®ï¼ˆOpenVINOã€TensorRTï¼‰å¯é€é Python API é€²è¡Œ
    // C++ å°ˆæ³¨æ–¼æ¨è«–åŸ·è¡Œå’Œæ•ˆèƒ½æ¸¬è©¦

    return 0;
}
```

**å®Œæ•´ç¯„ä¾‹**ï¼š`examples/cpp/embedded_optimization.cpp`

```bash
# å»ºç½®èˆ‡åŸ·è¡Œ
cd build && make embedded_optimization
./embedded_optimization model.onnx --device cuda:0 --benchmark
```

---

### å¾Œç«¯å·¥ç¨‹å¸«

> **ç›®æ¨™**ï¼šå»ºç«‹ç©©å®šçš„ AI æ¨è«–æœå‹™

#### ä½¿ç”¨æƒ…å¢ƒ

- éœ€è¦å»ºç«‹ REST API æ¨è«–æœå‹™
- éœ€è¦ç›£æ§æ¨è«–æ•ˆèƒ½å’Œè³‡æºä½¿ç”¨
- éœ€è¦è™•ç†é«˜ä¸¦ç™¼è«‹æ±‚

#### CLI å·¥å…·

```bash
# æŸ¥çœ‹ç³»çµ±è³‡è¨Š
ivit info

# åˆ—å‡ºå¯ç”¨è£ç½®
ivit devices

# æ•ˆèƒ½æ¸¬è©¦
ivit benchmark model.onnx --device cuda:0 --iterations 100

# åŸ·è¡Œæ¨è«–
ivit predict model.onnx image.jpg --output result.jpg

# æ¨¡å‹è½‰æ›
ivit convert model.onnx model.engine --format tensorrt --fp16

# å•Ÿå‹•æ¨è«–æœå‹™ï¼ˆREST APIï¼‰
ivit serve model.onnx --port 8080 --device cuda:0

# æ¨¡å‹è³‡è¨Š
ivit export model.onnx --info

# Model Zoo æ“ä½œ
ivit zoo list
ivit zoo search yolo
ivit zoo download yolov8n
```

#### Callback ç³»çµ±ï¼ˆç›£æ§æ•´åˆï¼‰

```python
import ivit
from ivit.core.callbacks import (
    CallbackManager,
    CallbackContext,
    CallbackEvent,
    FPSCounter,
    LatencyLogger,
    DetectionFilter,
)

# ============================================================
# æƒ…å¢ƒï¼šå»ºç«‹å…·å‚™å®Œæ•´ç›£æ§çš„æ¨è«–æœå‹™
# ============================================================

# è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ Model Zoo æ–¹ä¾¿ç¤ºç¯„ï¼‰
model = ivit.zoo.load("yolov8n", device="cuda:0")

# å»ºç«‹ Callback Manager
callback_manager = CallbackManager()

# --- å…§å»º Callback: FPS è¨ˆæ•¸å™¨ ---
fps_counter = FPSCounter(window_size=30)
callback_manager.register("infer_end", fps_counter)

# --- å…§å»º Callback: å»¶é²è¨˜éŒ„å™¨ ---
latency_logger = LatencyLogger()
callback_manager.register("infer_end", latency_logger)

# --- è‡ªå®šç¾© Callback: Prometheus æŒ‡æ¨™ ---
class PrometheusMetricsCallback:
    """å°‡æŒ‡æ¨™ç™¼é€åˆ° Prometheus"""

    def __init__(self):
        self.inference_count = 0
        self.total_latency = 0

    def __call__(self, ctx: CallbackContext):
        self.inference_count += 1
        self.total_latency += ctx.latency_ms

        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æœƒå°‡æŒ‡æ¨™ç™¼é€åˆ° Prometheus
        # prometheus_client.Counter('inference_total').inc()
        # prometheus_client.Histogram('inference_latency').observe(ctx.latency_ms)

prometheus_callback = PrometheusMetricsCallback()
callback_manager.register("infer_end", prometheus_callback)

# --- è‡ªå®šç¾© Callback: è­¦ç¤ºç³»çµ± ---
def alert_callback(ctx: CallbackContext):
    """å»¶é²éé«˜æ™‚ç™¼å‡ºè­¦ç¤º"""
    if ctx.latency_ms > 100:  # è¶…é 100ms
        print(f"[ALERT] é«˜å»¶é²è­¦å‘Š: {ctx.latency_ms:.1f}ms")
        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æœƒç™¼é€ Slack/Email é€šçŸ¥

callback_manager.register("infer_end", alert_callback)

# --- ä½¿ç”¨ Callback é€²è¡Œæ¨è«– ---
def inference_with_monitoring(image):
    """å¸¶ç›£æ§çš„æ¨è«–å‡½æ•¸"""
    # è§¸ç™¼æ¨è«–é–‹å§‹äº‹ä»¶
    ctx = CallbackContext(event="infer_start", model_name="yolov8n")
    callback_manager.trigger("infer_start", ctx)

    # åŸ·è¡Œæ¨è«–
    import time
    start = time.perf_counter()
    results = model(image)
    latency = (time.perf_counter() - start) * 1000

    # è§¸ç™¼æ¨è«–çµæŸäº‹ä»¶
    ctx = CallbackContext(
        event="infer_end",
        model_name="yolov8n",
        latency_ms=latency,
        detections=len(results)
    )
    callback_manager.trigger("infer_end", ctx)

    return results

# åŸ·è¡Œæ¨è«–
results = inference_with_monitoring("image.jpg")

# å–å¾—çµ±è¨ˆè³‡è¨Š
print(f"ç•¶å‰ FPS: {fps_counter.fps:.1f}")
print(f"å¹³å‡å»¶é²: {latency_logger.average_latency:.1f}ms")
print(f"ç¸½æ¨è«–æ¬¡æ•¸: {prometheus_callback.inference_count}")
```

#### å¯ç”¨çš„ Callback äº‹ä»¶

| äº‹ä»¶ | èªªæ˜ | Context å±¬æ€§ |
|------|------|--------------|
| `pre_process` | å‰è™•ç†é–‹å§‹ | image_shape |
| `post_process` | å¾Œè™•ç†å®Œæˆ | results |
| `infer_start` | æ¨è«–é–‹å§‹ | model_name |
| `infer_end` | æ¨è«–çµæŸ | latency_ms, preprocess_ms, inference_ms |
| `batch_start` | æ‰¹æ¬¡é–‹å§‹ | batch_size |
| `batch_end` | æ‰¹æ¬¡çµæŸ | total_latency |
| `stream_start` | ä¸²æµé–‹å§‹ | source |
| `stream_frame` | æ¯ä¸€å¹€ | frame_idx, fps |
| `stream_end` | ä¸²æµçµæŸ | total_frames |
| `model_loaded` | æ¨¡å‹è¼‰å…¥å®Œæˆ | model_path, device |
| `model_unloaded` | æ¨¡å‹å¸è¼‰ | model_path |

#### REST API æœå‹™ç¯„ä¾‹

```python
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import ivit
import numpy as np
import cv2

app = FastAPI(title="iVIT Inference Service")

# å…¨åŸŸæ¨¡å‹ï¼ˆæ‡‰ç”¨å•Ÿå‹•æ™‚è¼‰å…¥ï¼‰
model = None
fps_counter = None

@app.on_event("startup")
async def startup():
    global model, fps_counter
    from ivit.core.callbacks import FPSCounter

    model = ivit.zoo.load("yolov8n", device=ivit.devices.best())
    model.warmup(10)

    fps_counter = FPSCounter(window_size=100)
    model.on("infer_end", fps_counter)

    print(f"æ¨¡å‹å·²è¼‰å…¥è‡³ {model.device}")

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """åŸ·è¡Œç‰©ä»¶åµæ¸¬"""
    # è®€å–åœ–åƒ
    contents = await file.read()
    nparr = np.frombuffer(contents, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # æ¨è«–
    results = model(image)

    return JSONResponse({
        "success": True,
        "detections": results.to_dict()["detections"],
        "inference_time_ms": results.inference_time_ms,
        "current_fps": fps_counter.fps
    })

@app.get("/health")
async def health():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "current_fps": fps_counter.fps if fps_counter else 0
    }

@app.get("/stats")
async def stats():
    """æ•ˆèƒ½çµ±è¨ˆ"""
    return {
        "fps": fps_counter.fps,
        "device": str(model.device) if model else None,
    }

# å•Ÿå‹•: uvicorn server:app --host 0.0.0.0 --port 8080
```

#### C++ ç¯„ä¾‹

```cpp
#include "ivit/ivit.hpp"
#include <opencv2/opencv.hpp>
#include <mutex>
#include <deque>
#include <numeric>

using namespace ivit;

// FPS è¨ˆæ•¸å™¨ï¼ˆæ»‘å‹•è¦–çª—ï¼‰
class FPSCounter {
public:
    explicit FPSCounter(size_t window_size = 30)
        : window_size_(window_size) {}

    void record(double latency_ms) {
        std::lock_guard<std::mutex> lock(mutex_);
        latencies_.push_back(latency_ms);
        while (latencies_.size() > window_size_)
            latencies_.pop_front();
    }

    double fps() const {
        std::lock_guard<std::mutex> lock(mutex_);
        if (latencies_.empty()) return 0.0;
        double avg_ms = std::accumulate(latencies_.begin(), latencies_.end(), 0.0) / latencies_.size();
        return avg_ms > 0 ? 1000.0 / avg_ms : 0.0;
    }

private:
    size_t window_size_;
    std::deque<double> latencies_;
    mutable std::mutex mutex_;
};

// æ¨è«–æœå‹™
class InferenceService {
public:
    InferenceService(const std::string& model_path, const DeviceInfo& device)
        : fps_counter_(30) {

        // ä½¿ç”¨ load_model API
        LoadConfig config;
        config.device = device.id;
        model_ = load_model(model_path, config);

        // é ç†±
        cv::Mat dummy(480, 640, CV_8UC3);
        cv::randu(dummy, cv::Scalar(0), cv::Scalar(255));
        for (int i = 0; i < 10; ++i) {
            model_->predict(dummy);
        }
    }

    Results infer(const cv::Mat& image) {
        auto start = std::chrono::high_resolution_clock::now();
        auto results = model_->predict(image);
        auto end = std::chrono::high_resolution_clock::now();

        double latency = std::chrono::duration<double, std::milli>(end - start).count();
        fps_counter_.record(latency);

        return results;
    }

    double fps() const { return fps_counter_.fps(); }

private:
    std::shared_ptr<Model> model_;
    FPSCounter fps_counter_;
};

int main() {
    auto device = get_best_device();
    InferenceService service("yolov8n.onnx", device);

    cv::Mat image = cv::imread("test.jpg");
    auto results = service.infer(image);

    std::cout << "FPS: " << service.fps() << std::endl;
    std::cout << "Detections: " << results.detections.size() << std::endl;

    // Note: å®Œæ•´çš„ Callback ç³»çµ±å¯é€é Python API ä½¿ç”¨

    return 0;
}
```

**å®Œæ•´ç¯„ä¾‹**ï¼š`examples/cpp/backend_service.cpp`

```bash
# å»ºç½®èˆ‡åŸ·è¡Œ
cd build && make backend_service
./backend_service model.onnx --device cuda:0 --demo
```

---

### è³‡æ–™ç§‘å­¸å®¶

> **ç›®æ¨™**ï¼šå¿«é€Ÿé©—è­‰æ¨¡å‹æ•ˆæœï¼Œé€²è¡Œå¯¦é©—åˆ†æ

#### ä½¿ç”¨æƒ…å¢ƒ

- éœ€è¦å¿«é€Ÿè¼‰å…¥å’Œæ¸¬è©¦ä¸åŒæ¨¡å‹
- éœ€è¦åˆ†ææ¨è«–çµæœ
- éœ€è¦å°‡çµæœåŒ¯å‡ºç‚ºå„ç¨®æ ¼å¼

#### å¿«é€Ÿå¯¦é©—æµç¨‹

```python
import ivit

# ============================================================
# æƒ…å¢ƒï¼šå¾ Model Zoo å¿«é€Ÿè¼‰å…¥å’Œæ¸¬è©¦æ¨¡å‹
# ============================================================

# å¾ Model Zoo è¼‰å…¥é è¨“ç·´æ¨¡å‹ï¼ˆæ¨è–¦ï¼‰
model = ivit.zoo.load("yolov8n", device="cuda:0")

# åŸ·è¡Œæ¨è«–
results = model("image.jpg")

# å¿«é€Ÿåˆ†æçµæœ
print(f"åµæ¸¬åˆ° {len(results)} å€‹ç‰©ä»¶")
for det in results:
    print(f"  - {det.label}: {det.confidence:.2%}")
```

> **Model Zoo å®Œæ•´æ¸…å–®**ï¼šiVIT æä¾› 14 å€‹é è¨“ç·´æ¨¡å‹ï¼ŒåŒ…å«åµæ¸¬ã€åˆ†é¡ã€åˆ†å‰²ã€å§¿æ…‹ä¼°è¨ˆå››ç¨®ä»»å‹™ã€‚
> è©³ç´°çš„æ¨¡å‹åˆ—è¡¨ã€æ•ˆèƒ½æŒ‡æ¨™ã€API èªªæ˜è«‹åƒè€ƒ [Model Zoo å®Œæ•´æ¸…å–®](#model-zoo-å®Œæ•´æ¸…å–®)ã€‚

#### Results API è©³è§£

```python
import ivit
from ivit.core.result import Results

# ============================================================
# æƒ…å¢ƒï¼šå®Œæ•´çš„çµæœè™•ç†å’Œåˆ†æ
# ============================================================

# è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ Model Zooï¼‰
model = ivit.zoo.load("yolov8n")
results = model("image.jpg")

# --- åŸºæœ¬è³‡è¨Š ---
print(f"åµæ¸¬æ•¸é‡: {len(results)}")
print(f"æ¨è«–æ™‚é–“: {results.inference_time_ms:.1f}ms")
print(f"ä½¿ç”¨è£ç½®: {results.device_used}")
print(f"åœ–åƒå°ºå¯¸: {results.image_size}")

# --- è¿­ä»£åµæ¸¬çµæœ ---
for det in results:
    print(f"é¡åˆ¥: {det.label}")
    print(f"ä¿¡å¿ƒåº¦: {det.confidence:.2%}")
    print(f"é‚Šç•Œæ¡†: ({det.bbox.x1}, {det.bbox.y1}) - ({det.bbox.x2}, {det.bbox.y2})")
    print(f"é¢ç©: {det.bbox.area}")
    print("---")

# --- éæ¿¾åŠŸèƒ½ ---
# é€šç”¨éæ¿¾æ–¹æ³•
filtered = results.filter(confidence=0.9)
print(f"é«˜ä¿¡å¿ƒåº¦åµæ¸¬: {len(filtered)} é …")

filtered = results.filter(classes=["person", "car"])
print(f"ç‰¹å®šé¡åˆ¥åµæ¸¬: {len(filtered)} é …")

filtered = results.filter(confidence=0.8, classes=["person"], min_area=1000)
print(f"çµ„åˆéæ¿¾: {len(filtered)} é …")

# ç‰¹å®šéæ¿¾æ–¹æ³•
high_conf = results.filter_by_confidence(0.9)
persons = results.filter_by_class(["person"])
large_objects = results.filter_by_area(min_area=5000, max_area=50000)

# --- åºåˆ—åŒ– ---
# è½‰ç‚ºå­—å…¸
data = results.to_dict()

# è½‰ç‚º JSON
json_str = results.to_json()

# --- è¦–è¦ºåŒ– ---
# é¡¯ç¤ºçµæœï¼ˆé˜»å¡ï¼‰
results.show()

# é¡¯ç¤ºçµæœï¼ˆéé˜»å¡ï¼‰
results.show(wait=False)

# ç¹ªè£½çµæœä¸¦å–å¾—åœ–åƒ
plotted = results.plot(
    show_labels=True,
    show_confidence=True,
    line_width=2
)

# --- å„²å­˜çµæœ ---
# å„²å­˜è¦–è¦ºåŒ–åœ–åƒ
results.save("output.jpg")
results.save("output.png")

# å„²å­˜çµæœè³‡æ–™
results.save("output.json")

# å„²å­˜ YOLO æ ¼å¼æ¨™è¨»
results.save("output.txt")
```

#### åˆ†é¡çµæœè™•ç†

```python
model = ivit.zoo.load("resnet50")
results = model("cat.jpg")

# å–å¾— Top-1 çµæœ
top1 = results.top1
print(f"é æ¸¬é¡åˆ¥: {top1.label}")
print(f"ä¿¡å¿ƒåº¦: {top1.score:.2%}")

# å–å¾— Top-5 çµæœ
for i, cls in enumerate(results.top5):
    print(f"{i+1}. {cls.label}: {cls.score:.2%}")

# å–å¾— Top-K çµæœ
topk = results.topk(10)
```

#### åˆ†å‰²çµæœè™•ç†

```python
model = ivit.zoo.load("yolov8n-seg")
results = model("street.jpg")

# å–å¾—åˆ†å‰²é®ç½©
mask = results.segmentation_mask  # numpy array

# ä¸Šè‰²é®ç½©
colored_mask = results.colorize_mask()

# ç–ŠåŠ åˆ°åŸåœ–
overlay = results.overlay_mask(original_image, alpha=0.5)

# å–å¾—è¼ªå»“
contours = results.get_contours()
contours_person = results.get_contours(class_id=0)  # ç‰¹å®šé¡åˆ¥
```

#### æ¨¡å‹åŒ¯å‡ºæ ¼å¼æ¯”è¼ƒ

```python
from ivit.train import ModelExporter

# æ”¯æ´çš„åŒ¯å‡ºæ ¼å¼
formats = {
    "onnx": {
        "ç”¨é€”": "è·¨å¹³å°éƒ¨ç½²",
        "å„ªé»": "ç›¸å®¹æ€§æœ€é«˜",
        "é‡åŒ–": ["fp32", "fp16"],
    },
    "torchscript": {
        "ç”¨é€”": "PyTorch ç”Ÿæ…‹ç³»çµ±",
        "å„ªé»": "ç„¡éœ€ ONNX è½‰æ›",
        "é‡åŒ–": ["fp32"],
    },
    "openvino": {
        "ç”¨é€”": "Intel ç¡¬é«”å„ªåŒ–",
        "å„ªé»": "æœ€ä½³ Intel æ•ˆèƒ½",
        "é‡åŒ–": ["fp32", "fp16", "int8"],
    },
    "tensorrt": {
        "ç”¨é€”": "NVIDIA ç¡¬é«”å„ªåŒ–",
        "å„ªé»": "æœ€ä½³ NVIDIA æ•ˆèƒ½",
        "é‡åŒ–": ["fp32", "fp16", "int8"],
    },
}

# åŒ¯å‡ºç¯„ä¾‹
exporter = ModelExporter(model, device)
exporter.export("model.onnx", format="onnx", quantize="fp16")
```

#### C++ ç¯„ä¾‹

```cpp
#include "ivit/ivit.hpp"
#include <opencv2/opencv.hpp>
#include <map>
#include <numeric>

using namespace ivit;

int main() {
    // Step 1: ç³»çµ±æ¢ç´¢
    auto devices = list_devices();
    std::cout << "Available devices: " << devices.size() << std::endl;
    for (const auto& dev : devices) {
        std::cout << "  - " << dev.id << ": " << dev.name << std::endl;
    }

    // Note: Model Zoo å¯é€é Python API ä½¿ç”¨ (ivit.zoo.list_models())

    // Step 2: è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ load_model APIï¼‰
    auto device = get_best_device();
    LoadConfig config;
    config.device = device.id;
    auto model = load_model("yolov8n.onnx", config);

    // Step 3: çµæœåˆ†æ
    cv::Mat image = cv::imread("test.jpg");
    auto results = model->predict(image);

    std::cout << "Detection count: " << results.detections.size() << std::endl;
    std::cout << "Inference time: " << results.inference_time_ms << " ms" << std::endl;

    // éæ¿¾èˆ‡çµ±è¨ˆ
    std::map<std::string, int> class_counts;
    int high_conf_count = 0;

    for (const auto& det : results.detections) {
        class_counts[det.label]++;
        if (det.confidence > 0.9) high_conf_count++;

        std::cout << "  " << det.label << ": "
                  << (det.confidence * 100) << "%" << std::endl;
    }

    std::cout << "\nClass distribution:" << std::endl;
    for (const auto& [cls, count] : class_counts) {
        std::cout << "  " << cls << ": " << count << std::endl;
    }
    std::cout << "High confidence (>90%): " << high_conf_count << std::endl;

    // Step 4: æ‰¹æ¬¡è™•ç†
    std::vector<cv::Mat> batch_images;
    for (int i = 0; i < 5; ++i) {
        cv::Mat img(480, 640, CV_8UC3);
        cv::randu(img, cv::Scalar(0), cv::Scalar(255));
        batch_images.push_back(img);
    }

    std::vector<double> latencies;
    int total_detections = 0;

    for (const auto& img : batch_images) {
        auto res = model->predict(img);
        latencies.push_back(res.inference_time_ms);
        total_detections += res.detections.size();
    }

    double avg_latency = std::accumulate(latencies.begin(), latencies.end(), 0.0) / latencies.size();
    std::cout << "\nBatch stats:" << std::endl;
    std::cout << "  Total detections: " << total_detections << std::endl;
    std::cout << "  Avg latency: " << avg_latency << " ms" << std::endl;

    return 0;
}
```

**å®Œæ•´ç¯„ä¾‹**ï¼š`examples/cpp/data_analysis.cpp`

```bash
# å»ºç½®èˆ‡åŸ·è¡Œ
cd build && make data_analysis
./data_analysis model.onnx image.jpg --batch
```

---

## æ ¸å¿ƒ API åƒè€ƒ

### ivit æ¨¡çµ„

```python
import ivit

# è¼‰å…¥æ¨¡å‹
model = ivit.load(source, device="auto", task=None)

# è£ç½®æ¢ç´¢
ivit.devices()                    # åˆ—å‡ºæ‰€æœ‰è£ç½®
ivit.devices.cpu()                # å–å¾— CPU è£ç½®
ivit.devices.cuda()               # å–å¾— CUDA è£ç½®
ivit.devices.npu()                # å–å¾— NPU è£ç½®
ivit.devices.best()               # å–å¾—æœ€ä½³è£ç½®
ivit.devices.best("efficiency")   # å–å¾—æœ€é«˜æ•ˆç‡è£ç½®

# ç‰ˆæœ¬è³‡è¨Š
ivit.__version__                  # SDK ç‰ˆæœ¬
ivit.is_cpp_available()           # C++ ç¶å®šæ˜¯å¦å¯ç”¨
```

### Model é¡åˆ¥

```python
# æ¨è«–
results = model(image)                    # å–®å¼µåœ–åƒ
results = model.predict(image)            # åŒä¸Š
results = model.predict_batch([img1, img2])  # æ‰¹æ¬¡æ¨è«–

# ä¸²æµæ¨è«–
for results in model.stream("video.mp4"):
    results.show(wait=False)

# TTAï¼ˆæ¸¬è©¦æ™‚å¢å¼·ï¼‰
results = model.predict_tta(image, scales=[0.8, 1.0, 1.2])

# é…ç½®
model.configure_openvino(...)
model.configure_tensorrt(...)
model.configure_qnn(...)  # Qualcomm IQ Series (è¦åŠƒä¸­)

# å‰å¾Œè™•ç†
model.set_preprocessor(preprocessor)
model.set_postprocessor(postprocessor)

# é ç†±
model.warmup(iterations=10)

# Callback
model.on("infer_end", callback_func)
model.remove_callback("infer_end", callback_func)

# åº•å±¤å­˜å–
model.runtime                    # Runtime è³‡è¨Š
model.runtime_handle             # åº•å±¤ handle
model.infer_raw(inputs)          # åŸå§‹æ¨è«–
```

### Results é¡åˆ¥

```python
# åŸºæœ¬å±¬æ€§
len(results)                     # çµæœæ•¸é‡
results.inference_time_ms        # æ¨è«–æ™‚é–“
results.device_used              # ä½¿ç”¨è£ç½®
results.image_size               # åœ–åƒå°ºå¯¸

# åµæ¸¬çµæœ
results.detections               # æ‰€æœ‰åµæ¸¬
results.filter(confidence=0.9)   # éæ¿¾
results.filter_by_class(["person"])
results.filter_by_confidence(0.9)
results.filter_by_area(1000, 50000)

# åˆ†é¡çµæœ
results.top1                     # Top-1
results.top5                     # Top-5
results.topk(k)                  # Top-K

# åˆ†å‰²çµæœ
results.segmentation_mask        # åˆ†å‰²é®ç½©
results.colorize_mask()          # ä¸Šè‰²
results.overlay_mask(image)      # ç–ŠåŠ 
results.get_contours()           # è¼ªå»“

# åºåˆ—åŒ–
results.to_dict()                # è½‰å­—å…¸
results.to_json()                # è½‰ JSON

# è¦–è¦ºåŒ–
results.show()                   # é¡¯ç¤º
results.plot()                   # ç¹ªè£½
results.save(path)               # å„²å­˜
```

---

## æœ€ä½³å¯¦å‹™

### æ•ˆèƒ½å„ªåŒ–

1. **ä½¿ç”¨æ­£ç¢ºçš„è£ç½®**
   ```python
   # è‡ªå‹•é¸æ“‡æœ€ä½³è£ç½®
   model = ivit.zoo.load("yolov8n", device=ivit.devices.best())
   # æˆ–ä½¿ç”¨æœ¬åœ°æª”æ¡ˆ
   # model = ivit.load("model.onnx", device=ivit.devices.best())
   ```

2. **åŸ·è¡Œé ç†±**
   ```python
   model.warmup(iterations=10)
   ```

3. **ä½¿ç”¨ FP16 é‡åŒ–**
   ```python
   model.configure_tensorrt(fp16=True)
   ```

4. **æ‰¹æ¬¡æ¨è«–**
   ```python
   results = model.predict_batch([img1, img2, img3, img4])
   ```

### è¨˜æ†¶é«”ç®¡ç†

1. **åŠæ™‚é‡‹æ”¾æ¨¡å‹**
   ```python
   del model
   ```

2. **ä½¿ç”¨ä¸²æµæ¨¡å¼è™•ç†å½±ç‰‡**
   ```python
   for results in model.stream("video.mp4"):
       process(results)
   ```

### éŒ¯èª¤è™•ç†

1. **ç¸½æ˜¯åŒ…è£ try-except**
   ```python
   try:
       results = model(image)
   except ivit.IVITError as e:
       logger.error(f"æ¨è«–å¤±æ•—: {e}")
   ```

2. **é©—è­‰è¼¸å…¥**
   ```python
   if image is None or image.size == 0:
       raise ValueError("ç„¡æ•ˆçš„è¼¸å…¥åœ–åƒ")
   ```

---

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### Q: æ‰¾ä¸åˆ° CUDA è£ç½®

```
DeviceNotFoundError: CUDA device not found
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ç¢ºèª NVIDIA é©…å‹•ç¨‹å¼å·²å®‰è£ï¼š`nvidia-smi`
2. ç¢ºèª CUDA toolkit å·²å®‰è£
3. åŸ·è¡Œ `ivit.devices()` ç¢ºèªå¯ç”¨è£ç½®

#### Q: æ¨¡å‹è¼‰å…¥å¤±æ•—

```
ModelLoadError: Failed to load model
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ç¢ºèªæ¨¡å‹æª”æ¡ˆè·¯å¾‘æ­£ç¢º
2. ç¢ºèªæ¨¡å‹æ ¼å¼æ”¯æ´ï¼ˆ.onnx, .xml, .engineï¼‰
3. ç¢ºèªå°æ‡‰çš„å¾Œç«¯å·²å®‰è£

#### Q: æ¨è«–çµæœç•°å¸¸

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. ç¢ºèªè¼¸å…¥åœ–åƒæ ¼å¼æ­£ç¢ºï¼ˆBGR vs RGBï¼‰
2. ç¢ºèªå‰è™•ç†åƒæ•¸èˆ‡è¨“ç·´æ™‚ä¸€è‡´
3. æª¢æŸ¥æ¨¡å‹è¼¸å…¥å°ºå¯¸è¦æ±‚

#### Q: æ•ˆèƒ½ä¸å¦‚é æœŸ

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. åŸ·è¡Œ `model.warmup(10)` é ç†±
2. å•Ÿç”¨ FP16 é‡åŒ–
3. ä½¿ç”¨ `ivit benchmark` é€²è¡Œæ•ˆèƒ½æ¸¬è©¦
4. æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹å¼ä½”ç”¨ GPU

---

## Model Zoo å®Œæ•´æ¸…å–®

iVIT Model Zoo æä¾› 14 å€‹é è¨“ç·´æ¨¡å‹ï¼Œæ¶µè“‹å››ç¨®é›»è…¦è¦–è¦ºä»»å‹™ã€‚

### ç‰©ä»¶åµæ¸¬ (Detection)

| æ¨¡å‹åç¨± | è¼¸å…¥å°ºå¯¸ | mAP50-95 | åƒæ•¸é‡ | FLOPs | é©ç”¨å ´æ™¯ |
|----------|----------|----------|--------|-------|----------|
| `yolov8n` | 640Ã—640 | 37.3% | 3.2M | 8.7G | é‚Šç·£è£ç½®ã€å³æ™‚åµæ¸¬ |
| `yolov8s` | 640Ã—640 | 44.9% | 11.2M | 28.6G | å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºç‡ |
| `yolov8m` | 640Ã—640 | 50.2% | 25.9M | 78.9G | ä¸­ç­‰æº–ç¢ºç‡éœ€æ±‚ |
| `yolov8l` | 640Ã—640 | 52.9% | 43.7M | 165.2G | é«˜æº–ç¢ºç‡éœ€æ±‚ |
| `yolov8x` | 640Ã—640 | 53.9% | 68.2M | 257.8G | æœ€é«˜æº–ç¢ºç‡ã€ä¼ºæœå™¨éƒ¨ç½² |

### åœ–åƒåˆ†é¡ (Classification)

| æ¨¡å‹åç¨± | è¼¸å…¥å°ºå¯¸ | Top-1 | Top-5 | ä¾†æº | é©ç”¨å ´æ™¯ |
|----------|----------|-------|-------|------|----------|
| `yolov8n-cls` | 224Ã—224 | 69.0% | 88.3% | Ultralytics | é‚Šç·£è£ç½®åˆ†é¡ |
| `yolov8s-cls` | 224Ã—224 | 73.8% | 91.7% | Ultralytics | å¹³è¡¡æ•ˆèƒ½åˆ†é¡ |
| `resnet50` | 224Ã—224 | 76.1% | 92.9% | TorchVision | ç¶“å…¸åˆ†é¡æ¨¡å‹ |
| `mobilenetv3` | 224Ã—224 | 74.0% | 91.3% | TorchVision | è¡Œå‹•è£ç½®åˆ†é¡ |
| `efficientnet-b0` | 224Ã—224 | 77.1% | 93.3% | TorchVision | é«˜æ•ˆç‡åˆ†é¡ |

### èªæ„åˆ†å‰² (Segmentation)

| æ¨¡å‹åç¨± | è¼¸å…¥å°ºå¯¸ | mAP (Box) | mAP (Mask) | é©ç”¨å ´æ™¯ |
|----------|----------|-----------|------------|----------|
| `yolov8n-seg` | 640Ã—640 | 36.7% | 30.5% | é‚Šç·£è£ç½®åˆ†å‰² |
| `yolov8s-seg` | 640Ã—640 | 44.6% | 36.8% | å¹³è¡¡æ•ˆèƒ½åˆ†å‰² |

### å§¿æ…‹ä¼°è¨ˆ (Pose Estimation)

| æ¨¡å‹åç¨± | è¼¸å…¥å°ºå¯¸ | mAP (Pose) | é©ç”¨å ´æ™¯ |
|----------|----------|------------|----------|
| `yolov8n-pose` | 640Ã—640 | 50.4% | é‚Šç·£è£ç½®å§¿æ…‹ |
| `yolov8s-pose` | 640Ã—640 | 60.0% | å¹³è¡¡æ•ˆèƒ½å§¿æ…‹ |

### Model Zoo API åƒè€ƒ

> **åŸºæœ¬è¼‰å…¥æ–¹å¼**è«‹åƒè€ƒ [30 ç§’å¿«é€Ÿé«”é©—](#30-ç§’å¿«é€Ÿé«”é©—)

```python
import ivit

# ===== ç€è¦½æ¨¡å‹ =====

# åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
models = ivit.zoo.list_models()
# ['efficientnet-b0', 'mobilenetv3', 'resnet50', 'yolov8l', ...]

# æŒ‰ä»»å‹™éæ¿¾
ivit.zoo.list_models(task="detect")    # åµæ¸¬æ¨¡å‹ (5)
ivit.zoo.list_models(task="classify")  # åˆ†é¡æ¨¡å‹ (5)
ivit.zoo.list_models(task="segment")   # åˆ†å‰²æ¨¡å‹ (2)
ivit.zoo.list_models(task="pose")      # å§¿æ…‹æ¨¡å‹ (2)

# ===== æœå°‹æ¨¡å‹ =====

ivit.zoo.search("yolo")     # æœå°‹åç¨±å« "yolo" çš„æ¨¡å‹
ivit.zoo.search("edge")     # æœå°‹æ¨™ç±¤å« "edge" çš„æ¨¡å‹
ivit.zoo.search("fast")     # æœå°‹æ¨™ç±¤å« "fast" çš„æ¨¡å‹

# ===== æŸ¥è©¢æ¨¡å‹è³‡è¨Š =====

info = ivit.zoo.get_model_info("yolov8n")
print(f"ä»»å‹™: {info.task}")           # detect
print(f"è¼¸å…¥å°ºå¯¸: {info.input_size}") # (640, 640)
print(f"é¡åˆ¥æ•¸: {info.num_classes}")  # 80
print(f"æ•ˆèƒ½æŒ‡æ¨™: {info.metrics}")    # {'mAP50-95': 37.3, 'params_m': 3.2, ...}
print(f"æ¨™ç±¤: {info.tags}")           # ['yolo', 'detection', 'fast', 'edge']

# ===== è¼‰å…¥æ¨¡å‹ï¼ˆæŒ‡å®šè£ç½®ï¼‰=====

model = ivit.zoo.load("yolov8n", device="cuda:0")   # æŒ‡å®š GPU
model = ivit.zoo.load("yolov8n", device="cpu")      # æŒ‡å®š CPU
model = ivit.zoo.load("yolov8n", device="npu")      # æŒ‡å®š NPU
```

### æ¨¡å‹é¸æ“‡å»ºè­°

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | ç†ç”± |
|------|----------|------|
| é‚Šç·£è£ç½®å³æ™‚åµæ¸¬ | `yolov8n` | æœ€å°ã€æœ€å¿« |
| ä¸€èˆ¬åµæ¸¬æ‡‰ç”¨ | `yolov8s` | å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºç‡ |
| é«˜æº–ç¢ºç‡éœ€æ±‚ | `yolov8m` æˆ– `yolov8l` | æº–ç¢ºç‡æ›´é«˜ |
| è¡Œå‹•è£ç½®åˆ†é¡ | `mobilenetv3` | å°ˆç‚ºè¡Œå‹•è£ç½®å„ªåŒ– |
| é«˜ç²¾åº¦åˆ†é¡ | `efficientnet-b0` | Top-1 æœ€é«˜ |
| äººé«”å§¿æ…‹è¿½è¹¤ | `yolov8n-pose` | å³æ™‚å§¿æ…‹ä¼°è¨ˆ |

---

## é™„éŒ„

### A. æ”¯æ´çš„æ¨¡å‹æ ¼å¼

| æ ¼å¼ | å‰¯æª”å | èªªæ˜ |
|------|--------|------|
| ONNX | .onnx | é–‹æ”¾ç¥ç¶“ç¶²è·¯äº¤æ›æ ¼å¼ |
| OpenVINO IR | .xml, .bin | Intel å„ªåŒ–æ ¼å¼ |
| TensorRT Engine | .engine, .trt | NVIDIA å„ªåŒ–æ ¼å¼ |
| TorchScript | .pt, .pth | PyTorch æ ¼å¼ |

### B. ç’°å¢ƒè®Šæ•¸

| è®Šæ•¸ | èªªæ˜ | é è¨­å€¼ |
|------|------|--------|
| `IVIT_CACHE_DIR` | æ¨¡å‹å¿«å–ç›®éŒ„ | `~/.ivit/cache` |
| `IVIT_LOG_LEVEL` | æ—¥èªŒç­‰ç´š | `INFO` |
| `IVIT_DEFAULT_DEVICE` | é è¨­è£ç½® | `auto` |

### C. ç›¸é—œé€£çµ

- [GitHub Repository](https://github.com/innodisk-mannywang/ivit-sdk)
- [API æ–‡ä»¶](./api/api-spec.md)
- [æ¶æ§‹è¨­è¨ˆ](./architecture/adr-001-system.md)
- [ç”¢å“éœ€æ±‚](./development/prd.md)

---

## ç‰ˆæœ¬æ­·å²

| ç‰ˆæœ¬ | æ—¥æœŸ | èªªæ˜ |
|------|------|------|
| 1.0.0 | 2026-01-26 | åˆå§‹ç‰ˆæœ¬ |

---

> **éœ€è¦å”åŠ©ï¼Ÿ** è«‹å‰å¾€ [GitHub Issues](https://github.com/innodisk-mannywang/ivit-sdk/issues) æäº¤å•é¡Œã€‚
